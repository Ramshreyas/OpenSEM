{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60986d2",
   "metadata": {},
   "source": [
    "# OpenSEM Data Forge Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the **Data Forge** module in OpenSEM. \n",
    "We will cover:\n",
    "1.  Setting up the environment.\n",
    "2.  Running the default `TextForge` strategy.\n",
    "3.  Creating a custom Forge strategy (e.g., for a different data type or processing logic).\n",
    "\n",
    "## 1. Setup and Configuration\n",
    "\n",
    "First, we need to ensure we can import the `opensem` package from the `src` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "# Add the src directory to the python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"Project Root: {project_root}\")\n",
    "print(f\"Source Path: {src_path}\")\n",
    "\n",
    "# Import OpenSEM modules\n",
    "from opensem.forge import TextForge, BaseForge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90cd036",
   "metadata": {},
   "source": [
    "## 2. Initialize the Default Pipeline (TextForge)\n",
    "\n",
    "We will load the configuration for the `testsem` project (or create a mock one) and initialize the `TextForge`.\n",
    "`TextForge` is the default strategy for processing text files (.txt, .md, .pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596fa281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configuration (simulating what's in data_config.yaml)\n",
    "config = {\n",
    "    \"raw_data_dir\": os.path.join(project_root, \"data\", \"testsem\", \"raw\"),\n",
    "    \"processed_data_dir\": os.path.join(project_root, \"data\", \"testsem\", \"processed\"),\n",
    "    \"params\": {\n",
    "        \"teacher_model\": \"gemini-2.0-flash\",\n",
    "        \"max_chars_per_doc\": 1000, # Small limit for tutorial\n",
    "        \"chunk_size\": 500\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the Forge\n",
    "forge = TextForge(config)\n",
    "print(f\"Initialized {forge.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34842078",
   "metadata": {},
   "source": [
    "## 3. Execute the Standard Workflow\n",
    "\n",
    "We can run the individual steps manually to see what's happening, or call `forge.run()` for the full pipeline.\n",
    "Here, we'll step through it.\n",
    "\n",
    "### Step 3.1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98866855",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = forge.load_data()\n",
    "print(f\"Loaded {len(raw_data)} documents.\")\n",
    "if raw_data:\n",
    "    print(f\"First document preview:\\n{raw_data[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7ecf7",
   "metadata": {},
   "source": [
    "### Step 3.2: Synthesize Data\n",
    "\n",
    "This step uses the configured LLM (Gemini in this case) to generate instruction-output pairs.\n",
    "*Note: Ensure you have your `.env` file with `GEMINI_API_KEY` in the project root.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the mock synthesis if API key is missing, or real synthesis if present.\n",
    "# The TextForge class handles this logic internally.\n",
    "synthesized_data = forge.synthesize(raw_data)\n",
    "\n",
    "print(f\"Synthesized {len(synthesized_data)} examples.\")\n",
    "if synthesized_data:\n",
    "    print(\"Sample Example:\")\n",
    "    print(synthesized_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe32272",
   "metadata": {},
   "source": [
    "### Step 3.3: Format and Save\n",
    "\n",
    "Finally, we save the data to JSONL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37936cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forge.format_data(synthesized_data)\n",
    "print(f\"Data saved to {config['processed_data_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381bd168",
   "metadata": {},
   "source": [
    "## 4. Advanced: Custom PII Masking with LLMs\n",
    "\n",
    "The real power of OpenSEM is its extensibility. \n",
    "Suppose you want to create a dataset for **PII Redaction** (specifically removing names). Regex is brittle for names, so we will use an LLM to intelligently identify and redact them.\n",
    "\n",
    "We will create a `PIIMaskingForge` that:\n",
    "1.  Inherits from `TextForge`.\n",
    "2.  Overrides `synthesize` to ask the LLM to replace all names with `[PERSON]`.\n",
    "3.  Generates training pairs where `input` is the original text and `output` is the redacted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c5a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from opensem.forge import TextForge\n",
    "\n",
    "class PIIMaskingForge(TextForge):\n",
    "    def synthesize(self, raw_data: List[str]) -> List[Dict[str, Any]]:\n",
    "        print(\"Running PII Masking Synthesis (LLM-Based)...\")\n",
    "        \n",
    "        # Setup Gemini\n",
    "        load_dotenv()\n",
    "        api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if not api_key:\n",
    "            print(\"No API Key found. Returning empty list.\")\n",
    "            return []\n",
    "            \n",
    "        # Use the configured model or default\n",
    "        model_name = self.config.get('params', {}).get('teacher_model', 'gemini-2.0-flash')\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        \n",
    "        synthesized_data = []\n",
    "        \n",
    "        for doc in raw_data:\n",
    "            # We'll process the first 500 chars for this demo to save tokens\n",
    "            chunk = doc[:500]\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            You are a PII Redaction engine.\n",
    "            Replace all names of people in the following text with the token [PERSON].\n",
    "            Do not change anything else. Do not add any conversational text.\n",
    "            \n",
    "            Text:\n",
    "            {chunk}\n",
    "            \"\"\"\n",
    "            \n",
    "            try:\n",
    "                response = model.generate_content(prompt)\n",
    "                redacted_text = response.text.strip()\n",
    "                \n",
    "                synthesized_data.append({\n",
    "                    \"instruction\": \"Redact all person names from the text.\",\n",
    "                    \"input\": chunk,\n",
    "                    \"output\": redacted_text\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing chunk: {e}\")\n",
    "        \n",
    "        return synthesized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f08f23",
   "metadata": {},
   "source": [
    "## 5. Execute Custom Workflow\n",
    "\n",
    "Now we instantiate and run our `PIIMaskingForge` directly in the notebook.\n",
    "We'll use some sample text reminiscent of *War and Peace* to test the name redaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2c8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sample data\n",
    "sample_docs = [\n",
    "    \"Anna Pavlovna was coughing for the last few days. She had an attack of la grippe, as she said.\",\n",
    "    \"Prince Vasili entered, wearing his embroidered court uniform.\",\n",
    "    \"He spoke to his daughter, the beautiful Helene, about the party.\"\n",
    "]\n",
    "\n",
    "# Initialize our custom forge\n",
    "# We pass the model name in the config params\n",
    "custom_config = {\n",
    "    \"params\": {\n",
    "        \"teacher_model\": \"gemini-2.0-flash\"\n",
    "    }\n",
    "}\n",
    "forge_instance = PIIMaskingForge(config=custom_config)\n",
    "\n",
    "# Run synthesis\n",
    "results = forge_instance.synthesize(sample_docs)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nGenerated {len(results)} pairs.\\n\")\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"--- Example {i+1} ---\")\n",
    "    print(f\"Input:  {res['input']}\")\n",
    "    print(f\"Output: {res['output']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2a34c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you learned:\n",
    "1.  **Default Flow**: How `TextForge` uses an LLM to synthesize instruction pairs from raw text.\n",
    "2.  **Custom Flow**: How to implement a `PIIMaskingForge` to create a specific task dataset (Redaction) without using an LLM.\n",
    "3.  **Integration**: How to plug your custom class into the OpenSEM CLI using `data_config.yaml`.\n",
    "\n",
    "You can now build any kind of data pipeline (Image captioning, Time-series forecasting, etc.) by simply extending `BaseForge`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0eda8c",
   "metadata": {},
   "source": [
    "## 6. How to Use in Your Project\n",
    "\n",
    "To use this custom strategy in your actual OpenSEM project (via the CLI), follow these steps:\n",
    "\n",
    "1.  **Save the Class**: Save the `PIIMaskingForge` class code into a Python file within your project structure.\n",
    "    *   Example: `src/my_project/forge/pii_forge.py`\n",
    "\n",
    "2.  **Update Configuration**: Edit your `configs/<project_name>/data_config.yaml` file to point to this class.\n",
    "    ```yaml\n",
    "    # configs/my_project/data_config.yaml\n",
    "    forge_class: \"my_project.forge.pii_forge.PIIMaskingForge\"\n",
    "    params:\n",
    "      teacher_model: \"gemini-2.0-flash\"\n",
    "    ```\n",
    "\n",
    "3.  **Run the CLI**:\n",
    "    ```bash\n",
    "    python opensem.py run-forge --project my_project\n",
    "    ```\n",
    "\n",
    "OpenSEM will dynamically load your class and use it to process your data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
